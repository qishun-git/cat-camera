# Global cat face project configuration.
paths:
  # Root directory that holds all dataset folders.
  base_data_dir: data
  # Destination for unlabeled captures (may live under base_data_dir).
  unlabeled_dir: data/unlabeled
  # Destination for labeled training images.
  training_dir: data/training
  # Directory for rejected images when sorting.
  reject_dir: data/rejected
  # Directory that stores trained models and label maps.
  models_dir: models

vision:
  # Primary camera index shared by capture and recognition.
  camera_index: 1
  # Size (pixels) used for preprocessing/training/recognition.
  face_size: 224

capture:
  # Capture mode: "labeled" saves to a specific cat folder, "unlabeled" to sessions.
  mode: unlabeled
  # Whether to display the capture preview window.
  display_window: true
  # Automatically create session subfolders for unlabeled capture.
  auto_session_subfolders: true
  # Maximum number of images to keep per labeled cat.
  max_images_per_cat: 500
  # Maximum number of unlabeled images per session.
  max_unlabeled_images: 1000

detection:
  # Path to a YOLO ONNX model (relative paths resolve from repo root).
  model: pretrained_models/yolov5n.onnx
  # Input image size for YOLO preprocessing (single value or [width, height]).
  input_size: 640
  # YOLO class IDs to keep (COCO cat is 15); empty list keeps all.
  class_ids: [15]
  # Minimum confidence score for YOLO detections.
  conf_threshold: 0.5
  # IOU threshold used during YOLO non-max suppression.
  iou_threshold: 0.45
  # Optional ONNX Runtime providers (e.g., ["CPUExecutionProvider"]).
  providers: []

sorter:
  # Title for the sorting window.
  window_name: Sort Unlabeled
  # Sorter window width in pixels.
  window_width: 640
  # Sorter window height in pixels.
  window_height: 480
  # Initial X coordinate for the sorter window.
  window_x: 100
  # Initial Y coordinate for the sorter window.
  window_y: 100
  # Whether rejects are deleted from disk.
  delete_rejects: false
  # Image extensions the sorter will display.
  image_extensions: [".png", ".jpg", ".jpeg"]
  # Optional per-label cap applied after sorting (0 or null to disable).
  per_label_limit: 1000

training:
  # Label map filename saved under paths.models_dir.
  labels_filename: labels.json
  # Filename for the embedding-based recognizer (produced by train_embeddings.py).
  embedding_model_filename: embeddings.npz
  # Input size used by the embedding backbone (must match train/recognize).
  embedding_input_size: 224

recognition:
  # Embedding cosine similarity threshold when using the embedding method.
  embedding_threshold: 0.8
  # Filename for the embedding centroids (produced by train_embeddings.py).
  embedding_model_filename: embeddings.npz
  # Label map filename (defaults to training.labels_filename).
  labels_filename: labels.json

recorder:
  # Directory where detection-triggered video clips are saved (relative paths resolve from repo base).
  output_dir: data/clips
  # Minimum clip length in seconds (clips shorter than this are discarded).
  min_duration: 15.0
  # Maximum clip length in seconds (recording stops automatically once reached).
  max_duration: 300.0
  # Cooldown time in seconds before another clip can be recorded.
  cooldown: 5.0
  # Grace period (seconds) after the last detection before ending a clip.
  absence_grace: 5.0
  # Preferred output FPS (0 or null falls back to camera FPS).
  fps: 15
  # FourCC codec used by OpenCV VideoWriter (default mp4v -> MP4-friendly capture).
  codec: mp4v
  # Whether to show a preview window while recording clips.
  show_window: true
  # How often to run detection (seconds); 0 = every frame. Default 0.5s (~2 Hz).
  detection_interval: 0.5

clip_processing:
  # Directory containing recorded clips to process (defaults to recorder.output_dir).
  clips_dir: data/compressed_clips
  # Optional cap on the number of faces saved per clip (null/0 for unlimited).
  save_limit: 100
  # Number of frames to promote into training when a cat is auto-recognized.
  training_refresh_count: 10
  # Additional margin above recognition threshold required for automatic recognition.
  recognition_margin: 0
  # CRF used when re-encoding clips to H.265 (lower = higher quality/bigger files).
  compression_crf: 28
  # Seconds between watcher polling cycles.
  watch_interval: 5.0
